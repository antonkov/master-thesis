\chapter{Декодер}

Пример ссылок на литературные источники: \cite{hall-combinatorics,kudryashov-codingtheory,finding-and-counting-given-length-cycles,counting-short-cycles-of-quasi-cyclic-protograph-ldpc-codes,message-passing-algorithm-for-counting-short-cycles-in-graph,how-to-find-long-paths-efficiently,color-coding,algorithm-for-counting-for-counting-short-cycles-in-bipartite-graphs,on-the-number-of-cycles-in-a-graph,understanding-belief-propogation,mackay-codes}.


Проведение экспериментального исследования зависимости эффективности итеративного декодирования от некоторого
критерия подразумевает непосредственное моделирование передачи информации через канал с шумом посредством 
кодирования информации определенным МППЧ-кодом и последующим декодированием с помощью итеративного декодера.

Критерий, основанный на спектре циклов графа Таннера, побуждает к проведению исследования на иррегулярных
МППЧ-кодах. Еще одним фактором не в пользу скорости декодирования является размер кода --- который
должен быть выбран в соотвествии с длинами кодов, используемыми на практике, которые достаточно велики.
Кроме того, количество переданных кодовых слов при моделировании должны быть достаточно большим, чтобы оценка
отношения ошибочно-переданных блоком к общему числу переданных блоков (FER - frame error rate) была достаточно точна.

Моделирование передачи достаточного количества кодовых слов занимает минуты на современных 
компьютерах, используя наивную реализацию декодера на CPU или реализацию из доступных библиотек 
(таких как например реализация из Communication System Toolbox в Matlab). 
С учетом того, что каждый код должен быть протестирован на десятках различных отношений сигнал-шум (SNR ---
signal noise ratio), подход с использованием наивной реализации при имеющихся вычислительных ресурсах займет
недопустимо большое количество времени. 

Альтернативным подходом являются реализации итеративных декодеров с использованием
GPU.
Многие из доступных реализаций заточены под МППЧ-коды из стандартов. Большая часть использует параллелизм
на уровне декодирования одного кодового слова, что позволяет ускорить время между получением 
битовой последовательности и декодированного кодового слова
\cite{stressing-the-ber-simulation-of-ldpc-codes-in-the-error-floor-region-using-gpu-clusters}, 
но не использует тот факт что при оценке вероятности ошибки на блок передается большое количество кодовых
слов. В данном случае значительно более существенный выйгрыш позволяет получить параллелизм
на уровне набора кодовых слов, где вычислительные узлы разделены на группы, каждая из которых занимается
декодированием различных кодовых слов
\cite{opencl-cuda-algorithms-for-parallel-decoding-of-any-irregular-ldpc-code-using-gpu}.

К сожалению, итеративного GPU декодера, оптимизированного для получения оценки вероятности ошибки на блок,
не было найдено в открытых источниках сети Internet. Что побудило к созданию простого итеративного декодера
с использованием архитектуры CUDA, который позволил получить 60-70 кратное ускорение при моделировании
передачи большого числа кодовых слов иррегулярного МППЧ-кода.

\section{Количество кодовых слов при моделировании}

В первую очередь следует провести анализ количества кодовых слов, которое следует передать, чтобы 
статистически достоверно оценить вероятность ошибки на блок.

Пусть $P$ --- вероятность ошибки на блок и передача производилась до достижения $k$ ошибочно переданных блоков.
Тогда суммарно передано $N\approx \frac{k}{P}$ кодовых слов. Оценим дисперсию среднего арифметического при 
$N$ опытах. $X_i$ --- индикаторная случайная величина ошибки при передаче $i$-го кодового слова. 
\newcommand{\Expect}{\mathsf{E}}
\[
	\begin{split}
	\Variance \left({\frac{\sum_i{X_i}}{N}}\right) & =
	\Expect \left(\frac{\sum_i{X_i}}{N}\right)^2-\left(\Expect \left(\frac{\sum_i{X_i}}{N}\right)\right)^2 \\
	& = \frac{\Expect(\sum_i{X_i})^2}{N^2})-\left(\frac{\sum_i{\Expect(X_i)}}{N}\right)^2 \\
	& = \frac{\Expect(\sum_i{X_i})^2}{N^2})-\left(\frac{N \cdot P}{N}\right)^2 \\
	& = \frac{\sum_{i \neq j}{\Expect(X_i \cdot X_j)} + \sum_i{\Expect(X_i^2)}}{N^2}-P^2 \\
	& = \frac{N \cdot (N - 1) \cdot P^2 + N \cdot P}{N^2}-P^2 \\
	& = \frac{-N \cdot P^2 + N \cdot P}{N^2} \\
	& = \frac{P \cdot (1 - P)}{N}  = \frac{P^2 \cdot (1 - P)}{k}
	\end{split}
\]

Применяя Гауссовскую аппрокимацию биномиального распределения, можем говорить что пределы за $3\cdot \sigma$
маловероятны (вероятность порядка 0.001). Поэтому погрешность находится в пределах (учитывая что в реальности
$P \ll 1$):
\[
\pm \delta = 3 \cdot P \sqrt{\frac{1 - P}{k}} \approx P \cdot \frac{3}{\sqrt{k}} 
\]	 

Соответственно, например при $k=50$ получаем относительную погрешность $\approx 42\%$, 
а при $k=100$ --- $\approx 30\%$. При увеличении $k$ погрешность убывает обратно пропорционально корню.
Для проведения дальнейших исследований остановимся на $k=100$.
